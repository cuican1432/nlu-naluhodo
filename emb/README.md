### Embeddings Categories

We tested both using pre-trained word vectors and training word vectors on a larger email corpus [data source](https://www.cs.cmu.edu/~./enron/).

#### Pretrained Embeddings Include:

* glove.6B.100~300d.txt [data source](http://nlp.stanford.edu/data/glove.6B.zip "glove.6B.zip")

#### Customized Embeddings (train word vectors on the new corpus):

* GloVe_ec.100~300B.txt [data source](http://nlp.stanford.edu/data/glove.6B.zip "glove.6B.zip") and [reference](https://github.com/stanfordnlp/GloVe) 
