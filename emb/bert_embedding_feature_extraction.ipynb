{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bert-embedding-feature-extraction.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cuican1432/nlu-naluhodo/blob/master/emb/Bert_embedding_feature_extraction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "BJa63iRrNTzp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### This Notebook is meant to fit our target email corpus to bert pre-trained models and get featured embeddings.  \n",
        "\n",
        "[github](https://github.com/cuican1432/nlu-naluhodo/)"
      ]
    },
    {
      "metadata": {
        "id": "IW-XwUD5Mxbw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Get data source and tool using git clone datasource and bert [reference](https://towardsdatascience.com/nlp-extract-contextualized-word-embeddings-from-bert-keras-tf-67ef29f60a7b)"
      ]
    },
    {
      "metadata": {
        "id": "IfkIX6cdMrYd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "8dae5dbb-208d-4b35-bb70-b941438a8638"
      },
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/cuican1432/nlu-naluhodo.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlu-naluhodo'...\n",
            "remote: Enumerating objects: 141, done.\u001b[K\n",
            "remote: Counting objects: 100% (141/141), done.\u001b[K\n",
            "remote: Compressing objects: 100% (104/104), done.\u001b[K\n",
            "remote: Total 141 (delta 74), reused 91 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (141/141), 9.76 MiB | 16.38 MiB/s, done.\n",
            "Resolving deltas: 100% (74/74), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "lsoNiGAcPrL3",
        "colab_type": "code",
        "outputId": "fcbd982b-563a-47b1-96ee-c049d8a087a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        }
      },
      "cell_type": "code",
      "source": [
        "!rm -rf bert\n",
        "!git clone https://github.com/google-research/bert"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'bert'...\n",
            "remote: Enumerating objects: 325, done.\u001b[K\n",
            "remote: Total 325 (delta 0), reused 0 (delta 0), pack-reused 325\u001b[K\n",
            "Receiving objects: 100% (325/325), 263.74 KiB | 3.56 MiB/s, done.\n",
            "Resolving deltas: 100% (183/183), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LPbfDcE5P-oe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('bert/')\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "import codecs\n",
        "import collections\n",
        "import json\n",
        "import re\n",
        "import os\n",
        "import pprint\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import modeling\n",
        "import tokenization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9mUX54rcNzgB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Initial Bert"
      ]
    },
    {
      "metadata": {
        "id": "6Fg65bnIQBbG",
        "colab_type": "code",
        "outputId": "3e6236d7-923d-4a7d-ea17-4dfecabd33d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        }
      },
      "cell_type": "code",
      "source": [
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.105.112.26:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 13630750802181082949),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 13898235751463518273),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 11092036302565112902),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 12467158833123497378),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12738990852944582292),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 2001608644915291628),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9921810375171860759),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10388585691335703866),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2526419732646021171),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16904702335030619517),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 4491667866995537934)]\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "pYypaENeQFB2",
        "colab_type": "code",
        "outputId": "5c763b1a-c367-4170-8376-07240c094e8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "cell_type": "code",
      "source": [
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12'\n",
        "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL\n",
        "print('***** BERT pretrained directory: {} *****'.format(BERT_PRETRAINED_DIR))\n",
        "\n",
        "!gsutil ls $BERT_PRETRAINED_DIR\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** BERT pretrained directory: gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12 *****\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_config.json\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.meta\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/checkpoint\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Qg5DZ1GiQQkw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "LAYERS = [-1,-2,-3,-4]\n",
        "NUM_TPU_CORES = 8\n",
        "MAX_SEQ_LENGTH = 512\n",
        "BERT_CONFIG = BERT_PRETRAINED_DIR + '/bert_config.json'\n",
        "CHKPT_DIR = BERT_PRETRAINED_DIR + '/bert_model.ckpt'\n",
        "VOCAB_FILE = BERT_PRETRAINED_DIR + '/vocab.txt'\n",
        "INIT_CHECKPOINT = BERT_PRETRAINED_DIR + '/bert_model.ckpt'\n",
        "BATCH_SIZE = 128"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R-ZLub7OOBYM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Leverage Bert official suggested functions"
      ]
    },
    {
      "metadata": {
        "id": "2pf_5_zkQT6X",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class InputExample(object):\n",
        "  def __init__(self, unique_id, text_a, text_b=None):\n",
        "    self.unique_id = unique_id\n",
        "    self.text_a = text_a\n",
        "    self.text_b = text_b"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tMZtyweBQedy",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class InputFeatures(object):\n",
        "  \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "  def __init__(self, unique_id, tokens, input_ids, input_mask, input_type_ids):\n",
        "    self.unique_id = unique_id\n",
        "    self.tokens = tokens\n",
        "    self.input_ids = input_ids\n",
        "    self.input_mask = input_mask\n",
        "    self.input_type_ids = input_type_ids"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9AXLGkxJQkM5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def input_fn_builder(features, seq_length):\n",
        "  \"\"\"Creates an `input_fn` closure to be passed to TPUEstimator.\"\"\"\n",
        "\n",
        "  all_unique_ids = []\n",
        "  all_input_ids = []\n",
        "  all_input_mask = []\n",
        "  all_input_type_ids = []\n",
        "\n",
        "  for feature in features:\n",
        "    all_unique_ids.append(feature.unique_id)\n",
        "    all_input_ids.append(feature.input_ids)\n",
        "    all_input_mask.append(feature.input_mask)\n",
        "    all_input_type_ids.append(feature.input_type_ids)\n",
        "\n",
        "  def input_fn(params):\n",
        "    \"\"\"The actual input function.\"\"\"\n",
        "    batch_size = params[\"batch_size\"]\n",
        "\n",
        "    num_examples = len(features)\n",
        "\n",
        "    # This is for demo purposes and does NOT scale to large data sets. We do\n",
        "    # not use Dataset.from_generator() because that uses tf.py_func which is\n",
        "    # not TPU compatible. The right way to load data is with TFRecordReader.\n",
        "    d = tf.data.Dataset.from_tensor_slices({\n",
        "        \"unique_ids\":\n",
        "            tf.constant(all_unique_ids, shape=[num_examples], dtype=tf.int32),\n",
        "        \"input_ids\":\n",
        "            tf.constant(\n",
        "                all_input_ids, shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_mask\":\n",
        "            tf.constant(\n",
        "                all_input_mask,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "        \"input_type_ids\":\n",
        "            tf.constant(\n",
        "                all_input_type_ids,\n",
        "                shape=[num_examples, seq_length],\n",
        "                dtype=tf.int32),\n",
        "    })\n",
        "\n",
        "    d = d.batch(batch_size=batch_size, drop_remainder=False)\n",
        "    return d\n",
        "\n",
        "  return input_fn\n",
        "  \n",
        "def model_fn_builder(bert_config, init_checkpoint, layer_indexes, use_tpu,\n",
        "                     use_one_hot_embeddings):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    unique_ids = features[\"unique_ids\"]\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    input_type_ids = features[\"input_type_ids\"]\n",
        "\n",
        "    model = modeling.BertModel(\n",
        "        config=bert_config,\n",
        "        is_training=False,\n",
        "        input_ids=input_ids,\n",
        "        input_mask=input_mask,\n",
        "        token_type_ids=input_type_ids,\n",
        "        use_one_hot_embeddings=use_one_hot_embeddings)\n",
        "\n",
        "    if mode != tf.estimator.ModeKeys.PREDICT:\n",
        "      raise ValueError(\"Only PREDICT modes are supported: %s\" % (mode))\n",
        "\n",
        "    tvars = tf.trainable_variables()\n",
        "    scaffold_fn = None\n",
        "    (assignment_map,\n",
        "     initialized_variable_names) = modeling.get_assignment_map_from_checkpoint(\n",
        "         tvars, init_checkpoint)\n",
        "    if use_tpu:\n",
        "\n",
        "      def tpu_scaffold():\n",
        "        tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "        return tf.train.Scaffold()\n",
        "\n",
        "      scaffold_fn = tpu_scaffold\n",
        "    else:\n",
        "      tf.train.init_from_checkpoint(init_checkpoint, assignment_map)\n",
        "\n",
        "    tf.logging.info(\"**** Trainable Variables ****\")\n",
        "    for var in tvars:\n",
        "      init_string = \"\"\n",
        "      if var.name in initialized_variable_names:\n",
        "        init_string = \", *INIT_FROM_CKPT*\"\n",
        "      tf.logging.info(\"  name = %s, shape = %s%s\", var.name, var.shape,\n",
        "                      init_string)\n",
        "\n",
        "    all_layers = model.get_all_encoder_layers()\n",
        "\n",
        "    predictions = {\n",
        "        \"unique_id\": unique_ids,\n",
        "    }\n",
        "\n",
        "    for (i, layer_index) in enumerate(layer_indexes):\n",
        "      predictions[\"layer_output_%d\" % i] = all_layers[layer_index]\n",
        "\n",
        "    output_spec = tf.contrib.tpu.TPUEstimatorSpec(\n",
        "        mode=mode, predictions=predictions, scaffold_fn=scaffold_fn)\n",
        "    return output_spec\n",
        "\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gJYoo8WwQqnd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "def convert_examples_to_features(examples, seq_length, tokenizer):\n",
        "  \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
        "\n",
        "  features = []\n",
        "  for (ex_index, example) in enumerate(examples):\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "\n",
        "    tokens_b = None\n",
        "    if example.text_b:\n",
        "      tokens_b = tokenizer.tokenize(example.text_b)\n",
        "\n",
        "    if tokens_b:\n",
        "      # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "      # length is less than the specified length.\n",
        "      # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "      _truncate_seq_pair(tokens_a, tokens_b, seq_length - 3)\n",
        "    else:\n",
        "      # Account for [CLS] and [SEP] with \"- 2\"\n",
        "      if len(tokens_a) > seq_length - 2:\n",
        "        tokens_a = tokens_a[0:(seq_length - 2)]\n",
        "\n",
        "    # The convention in BERT is:\n",
        "    # (a) For sequence pairs:\n",
        "    #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "    #  type_ids: 0     0  0    0    0     0       0 0     1  1  1  1   1 1\n",
        "    # (b) For single sequences:\n",
        "    #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "    #  type_ids: 0     0   0   0  0     0 0\n",
        "    #\n",
        "    # Where \"type_ids\" are used to indicate whether this is the first\n",
        "    # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "    # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "    # embedding vector (and position vector). This is not *strictly* necessary\n",
        "    # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "    # it easier for the model to learn the concept of sequences.\n",
        "    #\n",
        "    # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "    # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "    # the entire model is fine-tuned.\n",
        "    tokens = []\n",
        "    input_type_ids = []\n",
        "    tokens.append(\"[CLS]\")\n",
        "    input_type_ids.append(0)\n",
        "    for token in tokens_a:\n",
        "      tokens.append(token)\n",
        "      input_type_ids.append(0)\n",
        "    tokens.append(\"[SEP]\")\n",
        "    input_type_ids.append(0)\n",
        "\n",
        "    if tokens_b:\n",
        "      for token in tokens_b:\n",
        "        tokens.append(token)\n",
        "        input_type_ids.append(1)\n",
        "      tokens.append(\"[SEP]\")\n",
        "      input_type_ids.append(1)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    while len(input_ids) < seq_length:\n",
        "      input_ids.append(0)\n",
        "      input_mask.append(0)\n",
        "      input_type_ids.append(0)\n",
        "\n",
        "    assert len(input_ids) == seq_length\n",
        "    assert len(input_mask) == seq_length\n",
        "    assert len(input_type_ids) == seq_length\n",
        "\n",
        "    if ex_index < 5:\n",
        "      tf.logging.info(\"*** Example ***\")\n",
        "      tf.logging.info(\"unique_id: %s\" % (example.unique_id))\n",
        "      tf.logging.info(\"tokens: %s\" % \" \".join(\n",
        "          [tokenization.printable_text(x) for x in tokens]))\n",
        "      tf.logging.info(\"input_ids: %s\" % \" \".join([str(x) for x in input_ids]))\n",
        "      tf.logging.info(\"input_mask: %s\" % \" \".join([str(x) for x in input_mask]))\n",
        "      tf.logging.info(\n",
        "          \"input_type_ids: %s\" % \" \".join([str(x) for x in input_type_ids]))\n",
        "\n",
        "    features.append(\n",
        "        InputFeatures(\n",
        "            unique_id=example.unique_id,\n",
        "            tokens=tokens,\n",
        "            input_ids=input_ids,\n",
        "            input_mask=input_mask,\n",
        "            input_type_ids=input_type_ids))\n",
        "  return features\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "  \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "  # This is a simple heuristic which will always truncate the longer sequence\n",
        "  # one token at a time. This makes more sense than truncating an equal percent\n",
        "  # of tokens from each, since if one sequence is very short then each token\n",
        "  # that's truncated likely contains more information than a longer sequence.\n",
        "  while True:\n",
        "    total_length = len(tokens_a) + len(tokens_b)\n",
        "    if total_length <= max_length:\n",
        "      break\n",
        "    if len(tokens_a) > len(tokens_b):\n",
        "      tokens_a.pop()\n",
        "    else:\n",
        "      tokens_b.pop()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUNdKt9vQuPe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def read_sequence(input_sentences):\n",
        "  examples = []\n",
        "  unique_id = 0\n",
        "  for sentence in input_sentences:\n",
        "    line = tokenization.convert_to_unicode(sentence)\n",
        "    examples.append(InputExample(unique_id=unique_id, text_a=line))\n",
        "    unique_id += 1\n",
        "  return examples"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H6Dy9e5tQxCL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_features(input_text, dim=768):\n",
        "  layer_indexes = LAYERS\n",
        "\n",
        "  bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG)\n",
        "\n",
        "  tokenizer = tokenization.FullTokenizer(\n",
        "      vocab_file=VOCAB_FILE, do_lower_case=True)\n",
        "\n",
        "  is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "  tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "  run_config = tf.contrib.tpu.RunConfig(\n",
        "      cluster=tpu_cluster_resolver,\n",
        "      tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "          num_shards=NUM_TPU_CORES,\n",
        "          per_host_input_for_training=is_per_host))\n",
        "\n",
        "  examples = read_sequence(input_text)\n",
        "\n",
        "  features = convert_examples_to_features(\n",
        "      examples=examples, seq_length=MAX_SEQ_LENGTH, tokenizer=tokenizer)\n",
        "\n",
        "  unique_id_to_feature = {}\n",
        "  for feature in features:\n",
        "    unique_id_to_feature[feature.unique_id] = feature\n",
        "\n",
        "  model_fn = model_fn_builder(\n",
        "      bert_config=bert_config,\n",
        "      init_checkpoint=INIT_CHECKPOINT,\n",
        "      layer_indexes=layer_indexes,\n",
        "      use_tpu=True,\n",
        "      use_one_hot_embeddings=True)\n",
        "\n",
        "  # If TPU is not available, this will fall back to normal Estimator on CPU\n",
        "  # or GPU.\n",
        "  estimator = tf.contrib.tpu.TPUEstimator(\n",
        "      use_tpu=True,\n",
        "      model_fn=model_fn,\n",
        "      config=run_config,\n",
        "      predict_batch_size=BATCH_SIZE,\n",
        "      train_batch_size=BATCH_SIZE)\n",
        "\n",
        "  input_fn = input_fn_builder(\n",
        "      features=features, seq_length=MAX_SEQ_LENGTH)\n",
        "\n",
        "  # Get features\n",
        "  for result in estimator.predict(input_fn, yield_single_examples=True):\n",
        "    unique_id = int(result[\"unique_id\"])\n",
        "    feature = unique_id_to_feature[unique_id]\n",
        "    output = collections.OrderedDict()\n",
        "    for (i, token) in enumerate(feature.tokens):\n",
        "      layers = []\n",
        "      for (j, layer_index) in enumerate(layer_indexes):\n",
        "        layer_output = result[\"layer_output_%d\" % j]\n",
        "        layer_output_flat = np.array([x for x in layer_output[i:(i + 1)].flat])\n",
        "        layers.append(layer_output_flat)\n",
        "      output[token] = sum(layers)[:dim]\n",
        "  \n",
        "  return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GUaNqLosObHM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Load data source from github `nlu-naluhodo`."
      ]
    },
    {
      "metadata": {
        "id": "EiqUerFJUiiJ",
        "colab_type": "code",
        "outputId": "f4c309ab-5943-4c2f-ffda-f9f1e40a1abd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('/content/nlu-naluhodo/data/beeapfinal/beeap_1.csv')\n",
        "df.values[2][-8]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'julia and steve here are some questions i ve sent to darrell on the tw cal border line pack sales i d like him to pull in the right people to get me the answers so we will be prepared if we need to explain these events darrell i thought i d better let your bosses know that i ve been putting more stuff on your already full plate thanks all df forwarded by drew fossum et s enron on am drew fossum pmto darrell schoolcraft et s enron@enroncc danny mccarty et s enron@enron steven harris et s enron@enron kevin hyatt enron@enronxgate subject tw gas sales privileged and confidential attorney client privilegein anticipation of potential litigation involving tw s operational activities please prepare an analysis for me of the reasons for tw s sale of excess natural gas at the california border i am aware of several of these sales and have been informed that excess pressure at the border is the basic reason for them i d like a more specific explanation that includes the following information what are the specific pressures and volume considerations that could make it operationally necessary to sell gas at the california border what is the process that is followed to make such a determination which individuals or groups are involved in determining whether an operational sale is necessary in what way have system operations changed since last year and how do those changes contribute to the increased frequency of such sales compared to previous years what alternatives to operational sales are considered before the decision to make a sale is reached thanks for your attention to this request please give me a call to discuss and please designate your response as privileged and confidential attorney client privileged '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "OxMB0koDOvO_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Leverage the function `get_features`,  you can directly use the function to build the embedding straight."
      ]
    },
    {
      "metadata": {
        "id": "hYj7oU3WQ0hl",
        "colab_type": "code",
        "outputId": "90988207-82cd-459a-e50a-8a5af857c985",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "cell_type": "code",
      "source": [
        "layer_indexes = LAYERS\n",
        "\n",
        "bert_config = modeling.BertConfig.from_json_file(BERT_CONFIG)\n",
        "\n",
        "tokenizer = tokenization.FullTokenizer(\n",
        "    vocab_file=VOCAB_FILE, do_lower_case=True)\n",
        "\n",
        "is_per_host = tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=is_per_host))\n",
        "\n",
        "model_fn = model_fn_builder(\n",
        "        bert_config=bert_config,\n",
        "        init_checkpoint=INIT_CHECKPOINT,\n",
        "        layer_indexes=layer_indexes,\n",
        "        use_tpu=True,\n",
        "        use_one_hot_embeddings=True)\n",
        "\n",
        "    # If TPU is not available, this will fall back to normal Estimator on CPU\n",
        "    # or GPU.\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    predict_batch_size=BATCH_SIZE,\n",
        "    train_batch_size=BATCH_SIZE)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f1bcfd52620>) includes params argument, but params are not passed to Estimator.\n",
            "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmpnsyw2ses\n",
            "INFO:tensorflow:Using config: {'_model_dir': '/tmp/tmpnsyw2ses', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.105.112.26:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f1bcf79a4e0>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.105.112.26:8470', '_evaluation_master': 'grpc://10.105.112.26:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=2, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f1bcf816978>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DFDbXRKiRAV4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Manipulated function `get_features` for our purpose adding labels and original docs. "
      ]
    },
    {
      "metadata": {
        "id": "QUhVhqn2vo8D",
        "colab_type": "code",
        "outputId": "cb8333d2-57ac-4c72-f02a-fc75ab2f1a28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 5340
        }
      },
      "cell_type": "code",
      "source": [
        "dim = 768\n",
        "examples = read_sequence(df.values[:,-1])\n",
        "\n",
        "features = convert_examples_to_features(\n",
        "    examples=examples, seq_length=MAX_SEQ_LENGTH, tokenizer=tokenizer)\n",
        "\n",
        "unique_id_to_feature = {}\n",
        "for feature in features:\n",
        "  unique_id_to_feature[feature.unique_id] = feature\n",
        "\n",
        "\n",
        "input_fn = input_fn_builder(\n",
        "    features=features, seq_length=MAX_SEQ_LENGTH)\n",
        "\n",
        "k = 0\n",
        "res = []\n",
        "# Get features\n",
        "for result in estimator.predict(input_fn, yield_single_examples=True):\n",
        "  unique_id = int(result[\"unique_id\"])\n",
        "  feature = unique_id_to_feature[unique_id]\n",
        "  output = collections.OrderedDict()\n",
        "  for (i, token) in enumerate(feature.tokens):\n",
        "    layers = []\n",
        "    for (j, layer_index) in enumerate(layer_indexes):\n",
        "      layer_output = result[\"layer_output_%d\" % j]\n",
        "      layer_output_flat = np.array([x for x in layer_output[i:(i + 1)].flat])\n",
        "      layers.append(layer_output_flat)  \n",
        "    output[token] = sum(layers)[:dim]\n",
        "  output['__labels__'] = df.values[k][-7:-1]\n",
        "  output['__email_contents__'] = df.values[k][-1]\n",
        "  k += 1 \n",
        "  res.append(output)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 0\n",
            "INFO:tensorflow:tokens: [CLS] message id java ##mail evans @ thy ##me date mon oct pd ##t from steven ke ##an @ en ##ron com to mark sc ##hr ##oed ##er @ en ##ron com kenneth lay @ en ##ron com joseph sutton @ en ##ron com jeff skill ##ing @ en ##ron com mark fr ##ever ##t @ en ##ron com john she ##rri ##ff @ en ##ron com subject translation of articles mi ##me version content type text plain char ##set us as ##ci ##i content transfer encoding bit x from steven j ke ##an x to mark sc ##hr ##oed ##er kenneth lay joseph w sutton jeff skill ##ing mark fr ##ever ##t john she ##rri ##ff x cc x bc ##c x folder kenneth lay dec notes folder ##s all documents x origin lay k x file ##name k ##lay ns ##f forward ##ed by steven j ke ##an ho ##u ee ##s on am karen den ##ne @ en ##ron am to steven j ke ##an ho ##u ee ##s @ ee ##s cc subject translation of articles forward ##ed by karen den ##ne corp en ##ron on am andrew morrison @ ec ##t am to karen den ##ne corp en ##ron @ en ##ron cc iona maclean lo ##n ec ##t @ ec ##t subject translation of articles karen here it is plenty of good houston input here as well as europe an excellent general article has resulted nice pictures too i ll get some original copies courier ##ed over to you asa ##p we are organising bi ling ##ual reprint ##s please let iona know how many you d like thanks andrew forward ##ed by andrew morrison lo ##n ec ##t on am en ##ron capital trade resources corp from g ##ls g ##ls ##lang ##ua ##ges ##er ##vic ##es @ com ##pus ##er ##ve com am to andrew morrison lo ##n ec ##t @ ec ##t cc subject translation of articles en ##ron doc [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4471 8909 9262 21397 6473 1030 15177 4168 3058 12256 13323 22851 2102 2013 7112 17710 2319 1030 4372 4948 4012 2000 2928 8040 8093 29099 2121 1030 4372 4948 4012 8856 3913 1030 4372 4948 4012 3312 11175 1030 4372 4948 4012 5076 8066 2075 1030 4372 4948 4012 2928 10424 22507 2102 1030 4372 4948 4012 2198 2016 18752 4246 1030 4372 4948 4012 3395 5449 1997 4790 2771 4168 2544 4180 2828 3793 5810 25869 13462 2149 2004 6895 2072 4180 4651 17181 2978 1060 2013 7112 1046 17710 2319 1060 2000 2928 8040 8093 29099 2121 8856 3913 3312 1059 11175 5076 8066 2075 2928 10424 22507 2102 2198 2016 18752 4246 1060 10507 1060 4647 2278 1060 19622 8856 3913 11703 3964 19622 2015 2035 5491 1060 4761 3913 1047 1060 5371 18442 1047 8485 24978 2546 2830 2098 2011 7112 1046 17710 2319 7570 2226 25212 2015 2006 2572 8129 7939 2638 1030 4372 4948 2572 2000 7112 1046 17710 2319 7570 2226 25212 2015 1030 25212 2015 10507 3395 5449 1997 4790 2830 2098 2011 8129 7939 2638 13058 4372 4948 2006 2572 4080 9959 1030 14925 2102 2572 2000 8129 7939 2638 13058 4372 4948 1030 4372 4948 10507 22347 22528 8840 2078 14925 2102 1030 14925 2102 3395 5449 1997 4790 8129 2182 2009 2003 7564 1997 2204 5395 7953 2182 2004 2092 2004 2885 2019 6581 2236 3720 2038 4504 3835 4620 2205 1045 2222 2131 2070 2434 4809 18092 2098 2058 2000 2017 17306 2361 2057 2024 21317 12170 17002 8787 25364 2015 3531 2292 22347 2113 2129 2116 2017 1040 2066 4283 4080 2830 2098 2011 4080 9959 8840 2078 14925 2102 2006 2572 4372 4948 3007 3119 4219 13058 2013 1043 4877 1043 4877 25023 6692 8449 2121 7903 2229 1030 4012 12207 2121 3726 4012 2572 2000 4080 9959 8840 2078 14925 2102 1030 14925 2102 10507 3395 5449 1997 4790 4372 4948 9986 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 1\n",
            "INFO:tensorflow:tokens: [CLS] message id java ##mail evans @ thy ##me date mon mar ps ##t from drew f ##oss ##um @ en ##ron com to darrell school ##craft @ en ##ron com subject t ##w gas sales privileged and confidential attorney client privilege cc danny mcc ##arty @ en ##ron com steven harris @ en ##ron com kevin h ##yat ##t @ en ##ron com mi ##me version content type text plain char ##set us as ##ci ##i content transfer encoding bit bc ##c danny mcc ##arty @ en ##ron com steven harris @ en ##ron com kevin h ##yat ##t @ en ##ron com x from drew f ##oss ##um x to darrell school ##craft x cc danny mcc ##arty steven harris kevin h ##yat ##t x bc ##c x folder drew f ##oss ##um dec june notes folder ##s all documents x origin f ##oss ##um d x file ##name d ##fo ##ss ##um ns ##f in anticipation of potential litigation involving t ##w s operational activities please prepare an analysis for me of the reasons for t ##w s sale of excess natural gas at the california border i am aware of several of these sales and have been informed that excess pressure at the border is the basic reason for them i d like a more specific explanation that includes the following information what are the specific pressures and volume considerations that could make it operational ##ly necessary to sell gas at the california border what is the process that is followed to make such a determination which individuals or groups are involved in determining whether an operational sale is necessary in what way have system operations changed since last year and how do those changes contribute to the increased frequency of such sales compared to previous years what alternatives to operational sales are considered before the decision to make a sale is reached thanks for your attention to this request please give me a call to discuss and please designate your response as privileged and confidential attorney client privileged [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4471 8909 9262 21397 6473 1030 15177 4168 3058 12256 9388 8827 2102 2013 3881 1042 15094 2819 1030 4372 4948 4012 2000 23158 2082 10419 1030 4372 4948 4012 3395 1056 2860 3806 4341 21598 1998 18777 4905 7396 14293 10507 6266 23680 23871 1030 4372 4948 4012 7112 5671 1030 4372 4948 4012 4901 1044 26139 2102 1030 4372 4948 4012 2771 4168 2544 4180 2828 3793 5810 25869 13462 2149 2004 6895 2072 4180 4651 17181 2978 4647 2278 6266 23680 23871 1030 4372 4948 4012 7112 5671 1030 4372 4948 4012 4901 1044 26139 2102 1030 4372 4948 4012 1060 2013 3881 1042 15094 2819 1060 2000 23158 2082 10419 1060 10507 6266 23680 23871 7112 5671 4901 1044 26139 2102 1060 4647 2278 1060 19622 3881 1042 15094 2819 11703 2238 3964 19622 2015 2035 5491 1060 4761 1042 15094 2819 1040 1060 5371 18442 1040 14876 4757 2819 24978 2546 1999 11162 1997 4022 15382 5994 1056 2860 1055 6515 3450 3531 7374 2019 4106 2005 2033 1997 1996 4436 2005 1056 2860 1055 5096 1997 9987 3019 3806 2012 1996 2662 3675 1045 2572 5204 1997 2195 1997 2122 4341 1998 2031 2042 6727 2008 9987 3778 2012 1996 3675 2003 1996 3937 3114 2005 2068 1045 1040 2066 1037 2062 3563 7526 2008 2950 1996 2206 2592 2054 2024 1996 3563 15399 1998 3872 16852 2008 2071 2191 2009 6515 2135 4072 2000 5271 3806 2012 1996 2662 3675 2054 2003 1996 2832 2008 2003 2628 2000 2191 2107 1037 9128 2029 3633 2030 2967 2024 2920 1999 12515 3251 2019 6515 5096 2003 4072 1999 2054 2126 2031 2291 3136 2904 2144 2197 2095 1998 2129 2079 2216 3431 9002 2000 1996 3445 6075 1997 2107 4341 4102 2000 3025 2086 2054 15955 2000 6515 4341 2024 2641 2077 1996 3247 2000 2191 1037 5096 2003 2584 4283 2005 2115 3086 2000 2023 5227 3531 2507 2033 1037 2655 2000 6848 1998 3531 24414 2115 3433 2004 21598 1998 18777 4905 7396 21598 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 2\n",
            "INFO:tensorflow:tokens: [CLS] message id java ##mail evans @ thy ##me date tu ##e mar ps ##t from drew f ##oss ##um @ en ##ron com to julia white @ en ##ron com steven january @ en ##ron com subject t ##w gas sales privileged and confidential attorney client privilege cc darrell school ##craft @ en ##ron com mi ##me version content type text plain char ##set us as ##ci ##i content transfer encoding bit bc ##c darrell school ##craft @ en ##ron com x from drew f ##oss ##um x to julia white steven january x cc darrell school ##craft x bc ##c x folder drew f ##oss ##um dec june notes folder ##s all documents x origin f ##oss ##um d x file ##name d ##fo ##ss ##um ns ##f julia and steve here are some questions i ve sent to darrell on the t ##w cal border line pack sales i d like him to pull in the right people to get me the answers so we will be prepared if we need to explain these events darrell i thought i d better let your bosses know that i ve been putting more stuff on your already full plate thanks all d ##f forward ##ed by drew f ##oss ##um et s en ##ron on am drew f ##oss ##um pm to darrell school ##craft et s en ##ron @ en ##ron cc danny mcc ##arty et s en ##ron @ en ##ron steven harris et s en ##ron @ en ##ron kevin h ##yat ##t en ##ron @ en ##ron ##x ##gate subject t ##w gas sales privileged and confidential attorney client privilege in anticipation of potential litigation involving t ##w s operational activities please prepare an analysis for me of the reasons for t ##w s sale of excess natural gas at the california border i am aware of several of these sales and have been informed that excess pressure at the border is the basic reason for them i d like a more specific explanation that includes the following information what are the specific pressures and volume considerations that could make it operational ##ly necessary to sell gas at the california border what is the process that is followed to make such a determination which individuals or groups are involved in determining whether an operational sale is necessary in what way have system operations changed since last year and how do those changes contribute to the increased frequency of such sales compared to previous years what alternatives to operational sales are considered before the decision to make a sale is reached thanks for your attention to this request please give me a call to discuss and please designate your response as privileged and confidential attorney client privileged [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4471 8909 9262 21397 6473 1030 15177 4168 3058 10722 2063 9388 8827 2102 2013 3881 1042 15094 2819 1030 4372 4948 4012 2000 6423 2317 1030 4372 4948 4012 7112 2254 1030 4372 4948 4012 3395 1056 2860 3806 4341 21598 1998 18777 4905 7396 14293 10507 23158 2082 10419 1030 4372 4948 4012 2771 4168 2544 4180 2828 3793 5810 25869 13462 2149 2004 6895 2072 4180 4651 17181 2978 4647 2278 23158 2082 10419 1030 4372 4948 4012 1060 2013 3881 1042 15094 2819 1060 2000 6423 2317 7112 2254 1060 10507 23158 2082 10419 1060 4647 2278 1060 19622 3881 1042 15094 2819 11703 2238 3964 19622 2015 2035 5491 1060 4761 1042 15094 2819 1040 1060 5371 18442 1040 14876 4757 2819 24978 2546 6423 1998 3889 2182 2024 2070 3980 1045 2310 2741 2000 23158 2006 1996 1056 2860 10250 3675 2240 5308 4341 1045 1040 2066 2032 2000 4139 1999 1996 2157 2111 2000 2131 2033 1996 6998 2061 2057 2097 2022 4810 2065 2057 2342 2000 4863 2122 2824 23158 1045 2245 1045 1040 2488 2292 2115 23029 2113 2008 1045 2310 2042 5128 2062 4933 2006 2115 2525 2440 5127 4283 2035 1040 2546 2830 2098 2011 3881 1042 15094 2819 3802 1055 4372 4948 2006 2572 3881 1042 15094 2819 7610 2000 23158 2082 10419 3802 1055 4372 4948 1030 4372 4948 10507 6266 23680 23871 3802 1055 4372 4948 1030 4372 4948 7112 5671 3802 1055 4372 4948 1030 4372 4948 4901 1044 26139 2102 4372 4948 1030 4372 4948 2595 5867 3395 1056 2860 3806 4341 21598 1998 18777 4905 7396 14293 1999 11162 1997 4022 15382 5994 1056 2860 1055 6515 3450 3531 7374 2019 4106 2005 2033 1997 1996 4436 2005 1056 2860 1055 5096 1997 9987 3019 3806 2012 1996 2662 3675 1045 2572 5204 1997 2195 1997 2122 4341 1998 2031 2042 6727 2008 9987 3778 2012 1996 3675 2003 1996 3937 3114 2005 2068 1045 1040 2066 1037 2062 3563 7526 2008 2950 1996 2206 2592 2054 2024 1996 3563 15399 1998 3872 16852 2008 2071 2191 2009 6515 2135 4072 2000 5271 3806 2012 1996 2662 3675 2054 2003 1996 2832 2008 2003 2628 2000 2191 2107 1037 9128 2029 3633 2030 2967 2024 2920 1999 12515 3251 2019 6515 5096 2003 4072 1999 2054 2126 2031 2291 3136 2904 2144 2197 2095 1998 2129 2079 2216 3431 9002 2000 1996 3445 6075 1997 2107 4341 4102 2000 3025 2086 2054 15955 2000 6515 4341 2024 2641 2077 1996 3247 2000 2191 1037 5096 2003 2584 4283 2005 2115 3086 2000 2023 5227 3531 2507 2033 1037 2655 2000 6848 1998 3531 24414 2115 3433 2004 21598 1998 18777 4905 7396 21598 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 3\n",
            "INFO:tensorflow:tokens: [CLS] message id java ##mail evans @ thy ##me date tu ##e mar ps ##t from drew f ##oss ##um @ en ##ron com to julia white @ en ##ron com steven january @ en ##ron com subject t ##w gas sales privileged and confidential attorney client privilege cc darrell school ##craft @ en ##ron com mi ##me version content type text plain char ##set us as ##ci ##i content transfer encoding bit bc ##c darrell school ##craft @ en ##ron com x from drew f ##oss ##um x to julia white julia white et s en ##ron @ en ##ron steven january steven january et s en ##ron @ en ##ron x cc darrell school ##craft darrell school ##craft et s en ##ron @ en ##ron x bc ##c x folder d ##fo ##ss ##um non privileged f ##oss ##um drew sent mail x origin f ##oss ##um d x file ##name d ##fo ##ss ##um non privileged ps ##t julia and steve here are some questions i ve sent to darrell on the t ##w cal border line pack sales i d like him to pull in the right people to get me the answers so we will be prepared if we need to explain these events darrell i thought i d better let your bosses know that i ve been putting more stuff on your already full plate thanks all d ##f forward ##ed by drew f ##oss ##um et s en ##ron on am drew f ##oss ##um pm to darrell school ##craft et s en ##ron @ en ##ron cc danny mcc ##arty et s en ##ron @ en ##ron steven harris et s en ##ron @ en ##ron kevin h ##yat ##t en ##ron @ en ##ron ##x ##gate subject t ##w gas sales privileged and confidential attorney client privilege in anticipation of potential litigation involving t ##w s operational activities please prepare an analysis for me of the reasons for t ##w s sale of excess natural gas at the california border i am aware of several of these sales and have been informed that excess pressure at the border is the basic reason for them i d like a more specific explanation that includes the following information what are the specific pressures and volume considerations that could make it operational ##ly necessary to sell gas at the california border what is the process that is followed to make such a determination which individuals or groups are involved in determining whether an operational sale is necessary in what way have system operations changed since last year and how do those changes contribute to the increased frequency of such sales compared to previous years what alternatives to operational sales are considered before the decision to make a sale is reached thanks for your attention to this request please give me a call to discuss and please designate your response as privileged and confidential attorney client privileged [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4471 8909 9262 21397 6473 1030 15177 4168 3058 10722 2063 9388 8827 2102 2013 3881 1042 15094 2819 1030 4372 4948 4012 2000 6423 2317 1030 4372 4948 4012 7112 2254 1030 4372 4948 4012 3395 1056 2860 3806 4341 21598 1998 18777 4905 7396 14293 10507 23158 2082 10419 1030 4372 4948 4012 2771 4168 2544 4180 2828 3793 5810 25869 13462 2149 2004 6895 2072 4180 4651 17181 2978 4647 2278 23158 2082 10419 1030 4372 4948 4012 1060 2013 3881 1042 15094 2819 1060 2000 6423 2317 6423 2317 3802 1055 4372 4948 1030 4372 4948 7112 2254 7112 2254 3802 1055 4372 4948 1030 4372 4948 1060 10507 23158 2082 10419 23158 2082 10419 3802 1055 4372 4948 1030 4372 4948 1060 4647 2278 1060 19622 1040 14876 4757 2819 2512 21598 1042 15094 2819 3881 2741 5653 1060 4761 1042 15094 2819 1040 1060 5371 18442 1040 14876 4757 2819 2512 21598 8827 2102 6423 1998 3889 2182 2024 2070 3980 1045 2310 2741 2000 23158 2006 1996 1056 2860 10250 3675 2240 5308 4341 1045 1040 2066 2032 2000 4139 1999 1996 2157 2111 2000 2131 2033 1996 6998 2061 2057 2097 2022 4810 2065 2057 2342 2000 4863 2122 2824 23158 1045 2245 1045 1040 2488 2292 2115 23029 2113 2008 1045 2310 2042 5128 2062 4933 2006 2115 2525 2440 5127 4283 2035 1040 2546 2830 2098 2011 3881 1042 15094 2819 3802 1055 4372 4948 2006 2572 3881 1042 15094 2819 7610 2000 23158 2082 10419 3802 1055 4372 4948 1030 4372 4948 10507 6266 23680 23871 3802 1055 4372 4948 1030 4372 4948 7112 5671 3802 1055 4372 4948 1030 4372 4948 4901 1044 26139 2102 4372 4948 1030 4372 4948 2595 5867 3395 1056 2860 3806 4341 21598 1998 18777 4905 7396 14293 1999 11162 1997 4022 15382 5994 1056 2860 1055 6515 3450 3531 7374 2019 4106 2005 2033 1997 1996 4436 2005 1056 2860 1055 5096 1997 9987 3019 3806 2012 1996 2662 3675 1045 2572 5204 1997 2195 1997 2122 4341 1998 2031 2042 6727 2008 9987 3778 2012 1996 3675 2003 1996 3937 3114 2005 2068 1045 1040 2066 1037 2062 3563 7526 2008 2950 1996 2206 2592 2054 2024 1996 3563 15399 1998 3872 16852 2008 2071 2191 2009 6515 2135 4072 2000 5271 3806 2012 1996 2662 3675 2054 2003 1996 2832 2008 2003 2628 2000 2191 2107 1037 9128 2029 3633 2030 2967 2024 2920 1999 12515 3251 2019 6515 5096 2003 4072 1999 2054 2126 2031 2291 3136 2904 2144 2197 2095 1998 2129 2079 2216 3431 9002 2000 1996 3445 6075 1997 2107 4341 4102 2000 3025 2086 2054 15955 2000 6515 4341 2024 2641 2077 1996 3247 2000 2191 1037 5096 2003 2584 4283 2005 2115 3086 2000 2023 5227 3531 2507 2033 1037 2655 2000 6848 1998 3531 24414 2115 3433 2004 21598 1998 18777 4905 7396 21598 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:unique_id: 4\n",
            "INFO:tensorflow:tokens: [CLS] message id java ##mail evans @ thy ##me date mon mar ps ##t from drew f ##oss ##um @ en ##ron com to darrell school ##craft @ en ##ron com subject t ##w gas sales privileged and confidential attorney client privilege cc danny mcc ##arty @ en ##ron com steven harris @ en ##ron com kevin h ##yat ##t @ en ##ron com mi ##me version content type text plain char ##set us as ##ci ##i content transfer encoding bit bc ##c danny mcc ##arty @ en ##ron com steven harris @ en ##ron com kevin h ##yat ##t @ en ##ron com x from drew f ##oss ##um x to darrell school ##craft darrell school ##craft et s en ##ron @ en ##ron x cc danny mcc ##arty danny mcc ##arty et s en ##ron @ en ##ron steven harris steven harris et s en ##ron @ en ##ron kevin h ##yat ##t kevin h ##yat ##t en ##ron @ en ##ron ##x ##gate x bc ##c x folder d ##fo ##ss ##um non privileged f ##oss ##um drew sent mail x origin f ##oss ##um d x file ##name d ##fo ##ss ##um non privileged ps ##t in anticipation of potential litigation involving t ##w s operational activities please prepare an analysis for me of the reasons for t ##w s sale of excess natural gas at the california border i am aware of several of these sales and have been informed that excess pressure at the border is the basic reason for them i d like a more specific explanation that includes the following information what are the specific pressures and volume considerations that could make it operational ##ly necessary to sell gas at the california border what is the process that is followed to make such a determination which individuals or groups are involved in determining whether an operational sale is necessary in what way have system operations changed since last year and how do those changes contribute to the increased frequency of such sales compared to previous years what alternatives to operational sales are considered before the decision to make a sale is reached thanks for your attention to this request please give me a call to discuss and please designate your response as privileged and confidential attorney client privileged [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4471 8909 9262 21397 6473 1030 15177 4168 3058 12256 9388 8827 2102 2013 3881 1042 15094 2819 1030 4372 4948 4012 2000 23158 2082 10419 1030 4372 4948 4012 3395 1056 2860 3806 4341 21598 1998 18777 4905 7396 14293 10507 6266 23680 23871 1030 4372 4948 4012 7112 5671 1030 4372 4948 4012 4901 1044 26139 2102 1030 4372 4948 4012 2771 4168 2544 4180 2828 3793 5810 25869 13462 2149 2004 6895 2072 4180 4651 17181 2978 4647 2278 6266 23680 23871 1030 4372 4948 4012 7112 5671 1030 4372 4948 4012 4901 1044 26139 2102 1030 4372 4948 4012 1060 2013 3881 1042 15094 2819 1060 2000 23158 2082 10419 23158 2082 10419 3802 1055 4372 4948 1030 4372 4948 1060 10507 6266 23680 23871 6266 23680 23871 3802 1055 4372 4948 1030 4372 4948 7112 5671 7112 5671 3802 1055 4372 4948 1030 4372 4948 4901 1044 26139 2102 4901 1044 26139 2102 4372 4948 1030 4372 4948 2595 5867 1060 4647 2278 1060 19622 1040 14876 4757 2819 2512 21598 1042 15094 2819 3881 2741 5653 1060 4761 1042 15094 2819 1040 1060 5371 18442 1040 14876 4757 2819 2512 21598 8827 2102 1999 11162 1997 4022 15382 5994 1056 2860 1055 6515 3450 3531 7374 2019 4106 2005 2033 1997 1996 4436 2005 1056 2860 1055 5096 1997 9987 3019 3806 2012 1996 2662 3675 1045 2572 5204 1997 2195 1997 2122 4341 1998 2031 2042 6727 2008 9987 3778 2012 1996 3675 2003 1996 3937 3114 2005 2068 1045 1040 2066 1037 2062 3563 7526 2008 2950 1996 2206 2592 2054 2024 1996 3563 15399 1998 3872 16852 2008 2071 2191 2009 6515 2135 4072 2000 5271 3806 2012 1996 2662 3675 2054 2003 1996 2832 2008 2003 2628 2000 2191 2107 1037 9128 2029 3633 2030 2967 2024 2920 1999 12515 3251 2019 6515 5096 2003 4072 1999 2054 2126 2031 2291 3136 2904 2144 2197 2095 1998 2129 2079 2216 3431 9002 2000 1996 3445 6075 1997 2107 4341 4102 2000 3025 2086 2054 15955 2000 6515 4341 2024 2641 2077 1996 3247 2000 2191 1037 5096 2003 2584 4283 2005 2115 3086 2000 2023 5227 3531 2507 2033 1037 2655 2000 6848 1998 3531 24414 2115 3433 2004 21598 1998 18777 4905 7396 21598 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:input_type_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:Could not find trained model in model_dir: /tmp/tmpnsyw2ses, running initialization to predict.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.105.112.26:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 13630750802181082949)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 13898235751463518273)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 11092036302565112902)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 12467158833123497378)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 12738990852944582292)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 2001608644915291628)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 9921810375171860759)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 10388585691335703866)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 2526419732646021171)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 16904702335030619517)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 4491667866995537934)\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From bert/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Enqueue next (1) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Stop infeed thread controller\n",
            "INFO:tensorflow:Shutting down InfeedController thread.\n",
            "INFO:tensorflow:InfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Infeed thread finished, shutting down.\n",
            "INFO:tensorflow:infeed marked as finished\n",
            "INFO:tensorflow:Stop output thread controller\n",
            "INFO:tensorflow:Shutting down OutfeedController thread.\n",
            "INFO:tensorflow:OutfeedController received shutdown signal, stopping.\n",
            "INFO:tensorflow:Outfeed thread finished, shutting down.\n",
            "INFO:tensorflow:outfeed marked as finished\n",
            "INFO:tensorflow:Shutdown TPU system.\n",
            "INFO:tensorflow:prediction_loop marked as finished\n",
            "INFO:tensorflow:prediction_loop marked as finished\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6QpkJHB6zvBs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sanity check and tried to fit result dictionary to matrix\n",
        "# mx = 0\n",
        "# for i in range(1702):\n",
        "#   if mx < len(res[i]):\n",
        "#     mx = len(res[i])\n",
        "    \n",
        "\n",
        "# x_embeddings = np.zeros((1702, 345, 768))\n",
        "# l  = ['[CLS]', '__labels__', '__email_contents__', '[SEP]']\n",
        "\n",
        "# for idx in range(1702):\n",
        "#   j = 0\n",
        "#   for key, values in res[idx].items():\n",
        "#     if key not in l:\n",
        "#       x_embeddings[idx,j] = values\n",
        "#       j += 1\n",
        "      \n",
        "# y_labels = np.zeros((1702,6))\n",
        "# for idx in range(1702):\n",
        "#   y_labels[idx] = res[idx]['__labels__']\n",
        "  \n",
        "  \n",
        "# x_contents = []\n",
        "# for idx in range(1702):\n",
        "#   x_contents += [res[idx]['__email_contents__']]\n",
        "  \n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "U4vevmbKQwew",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Dump result dictionary to pickle file as output. "
      ]
    },
    {
      "metadata": {
        "id": "1iVY4IKCKRBa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import pickle \n",
        "pickle.dump(res, open( \"beeap_1_embeddings.p\", \"wb\" ))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
