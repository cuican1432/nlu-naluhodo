{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "bert-multi-label-classification-example.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cuican1432/nlu-naluhodo/blob/master/bert_multi_label_classification_example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aL9nyXHJo0gk",
        "colab_type": "text"
      },
      "source": [
        "Load github repo of this project [github](https://github.com/cuican1432/nlu-naluhodo)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pY9dnvAn_me",
        "colab_type": "code",
        "outputId": "6a136eb8-9fe4-48c4-8a6c-a333ea9981d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        }
      },
      "source": [
        "import sys\n",
        "!rm -r nlu-naluhodo; rm -r bert_repo\n",
        "!git clone https://github.com/cuican1432/nlu-naluhodo.git\n",
        "!cp -r /content/nlu-naluhodo/models/bert-tpu bert_repo\n",
        "if not 'bert_repo' in sys.path:\n",
        "  sys.path += ['bert_repo']"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'nlu-naluhodo'...\n",
            "remote: Enumerating objects: 150, done.\u001b[K\n",
            "remote: Counting objects: 100% (150/150), done.\u001b[K\n",
            "remote: Compressing objects: 100% (109/109), done.\u001b[K\n",
            "remote: Total 372 (delta 91), reused 88 (delta 39), pack-reused 222\u001b[K\n",
            "Receiving objects: 100% (372/372), 10.08 MiB | 16.54 MiB/s, done.\n",
            "Resolving deltas: 100% (209/209), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XPrw13uBpaFU",
        "colab_type": "code",
        "outputId": "f0f11eb5-c5ab-44cc-8c24-d0667f7192f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "source": [
        "import datetime\n",
        "import json\n",
        "import os\n",
        "import pprint\n",
        "import random\n",
        "import string\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "assert 'COLAB_TPU_ADDR' in os.environ, 'ERROR: Not connected to a TPU runtime; please see the first cell in this notebook for instructions!'\n",
        "TPU_ADDRESS = 'grpc://' + os.environ['COLAB_TPU_ADDR']\n",
        "print('TPU address is', TPU_ADDRESS)\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "with tf.Session(TPU_ADDRESS) as session:\n",
        "  print('TPU devices:')\n",
        "  pprint.pprint(session.list_devices())\n",
        "\n",
        "  # Upload credentials to TPU.\n",
        "  with open('/content/adc.json', 'r') as f:\n",
        "    auth_info = json.load(f)\n",
        "  tf.contrib.cloud.configure_gcs(session, credentials=auth_info)\n",
        "  # Now credentials are set for all future sessions on this TPU."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TPU address is grpc://10.2.133.226:8470\n",
            "TPU devices:\n",
            "[_DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:CPU:0, CPU, -1, 15713879670663694203),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 17667312031214739020),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7259243042589462203),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 3063187338904789856),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 2773942055403689470),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5664809989900726935),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 100087510466400996),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 7264435289128316276),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 8767581307475779826),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 932489684604596695),\n",
            " _DeviceAttributes(/job:tpu_worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 4537793796198685419)]\n",
            "\n",
            "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVdKU6bYpzt8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import modeling\n",
        "import optimization\n",
        "import run_multilabels_classifier\n",
        "import tokenization\n",
        "\n",
        "# import tfhub \n",
        "# import tensorflow_hub as hub\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-PqJbndt9FJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "beeap_1 = pd.read_csv('/content/nlu-naluhodo/data/beeapfinal/beeap_1.csv')\n",
        "beeap_1.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "for i in beeap_1.columns[1:]:\n",
        "    beeap_1[i] = beeap_1[i].astype(np.float64, errors='ignore')\n",
        "    \n",
        "data_index = pickle.load(open('/content/nlu-naluhodo/data/data_upsample_index.p', 'rb'))\n",
        "index = [i for i in range(1702)]\n",
        "val_idx = np.unique(data_index['val'][0])\n",
        "test_idx = np.unique(data_index['test'])\n",
        "\n",
        "train_exp = np.concatenate([test_idx.flatten(),val_idx.flatten()], axis=0)\n",
        "\n",
        "train_idx = [i for i in index if i not in train_exp]\n",
        "\n",
        "# train_idx = np.concatenate([train_idx.flatten(),val_idx.flatten()], axis=0)\n",
        "beeap_1.iloc[train_idx][['Contents','1', '2', '3', '4', '5', '6']].to_csv('/content/nlu-naluhodo/data/train.csv', index = False)\n",
        "beeap_1.iloc[val_idx][['Contents','1', '2', '3', '4', '5', '6']].to_csv('/content/nlu-naluhodo/data/val.csv', index = False)\n",
        "beeap_1.iloc[data_index['test']][['Contents','1', '2', '3', '4', '5', '6']].to_csv('/content/nlu-naluhodo/data/test.csv', index = False)\n",
        "\n",
        "\n",
        "test = beeap_1.iloc[data_index['test']][['Contents','1', '2', '3', '4', '5', '6']].values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "URkBZKaf4s5h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# beeap_1 = pd.read_csv('/content/nlu-naluhodo/data/beeapfinal/beeap_1.csv')\n",
        "# data_index = pickle.load(open('/content/nlu-naluhodo/data/data_upsample_index.p', 'rb'))\n",
        "\n",
        "# train_sample = data_index['train'][0][0:500]\n",
        "# val_sample = data_index['val'][0][0:100]\n",
        "\n",
        "\n",
        "# beeap_1.drop('Unnamed: 0', axis=1, inplace=True)\n",
        "# for i in beeap_1.columns[1:]:\n",
        "#     beeap_1[i] = beeap_1[i].astype(np.float64, errors='ignore')\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "# beeap_1.iloc[train_sample][['Contents','1', '2', '3', '4', '5', '6']].to_csv('/content/nlu-naluhodo/data/train.csv', index = False)\n",
        "# beeap_1.iloc[val_sample][['Contents','1', '2', '3', '4', '5', '6']].to_csv('/content/nlu-naluhodo/data/val.csv', index = False)\n",
        "# beeap_1.iloc[data_index['test']][['Contents','1', '2', '3', '4', '5', '6']].to_csv('/content/nlu-naluhodo/data/test.csv', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6QrGnhPxo4pr",
        "colab_type": "code",
        "outputId": "16f97581-eb8d-4ba7-c795-4a59a08bd748",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "TASK = 'MultiLabelText-1' #@param {type:\"string\"}\n",
        "\n",
        "TASK_DATA_DIR = '/content/nlu-naluhodo/data/'\n",
        "print('***** Task data directory: {} *****'.format(TASK_DATA_DIR))\n",
        "!ls $TASK_DATA_DIR\n",
        "\n",
        "BUCKET = 'nlu-naluhodo-bert' #@param {type:\"string\"}\n",
        "assert BUCKET, 'Must specify an existing GCS bucket name'\n",
        "OUTPUT_DIR = 'gs://{}/bert-tfhub/models/{}'.format(BUCKET, TASK)\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))\n",
        "\n",
        "# Available pretrained model checkpoints:\n",
        "#   uncased_L-12_H-768_A-12: uncased BERT base model\n",
        "#   uncased_L-24_H-1024_A-16: uncased BERT large model\n",
        "#   cased_L-12_H-768_A-12: cased BERT large model\n",
        "BERT_MODEL = 'uncased_L-12_H-768_A-12' #@param {type:\"string\"}\n",
        "BERT_PRETRAINED_DIR = 'gs://cloud-tpu-checkpoints/bert/' + BERT_MODEL\n",
        "!gsutil ls $BERT_PRETRAINED_DIR\n",
        "BERT_MODEL_HUB = 'https://tfhub.dev/google/bert_' + BERT_MODEL + '/1'"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Task data directory: /content/nlu-naluhodo/data/ *****\n",
            "beeapfinal  classes.txt  data_upsample_index.p\ttest.csv  train.csv  val.csv\n",
            "***** Model output directory: gs://nlu-naluhodo-bert/bert-tfhub/models/MultiLabelText-1 *****\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_config.json\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.data-00000-of-00001\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.index\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/bert_model.ckpt.meta\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/checkpoint\n",
            "gs://cloud-tpu-checkpoints/bert/uncased_L-12_H-768_A-12/vocab.txt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKgX6wWWGzGP",
        "colab_type": "code",
        "outputId": "da8a4094-e5da-413c-a3a2-be0f859df786",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        }
      },
      "source": [
        "# Model Hyper Parameters\n",
        "NUM_TRAIN_EPOCHS = 400.0\n",
        "MAX_SEQ_LENGTH = 256\n",
        "\n",
        "TRAIN_BATCH_SIZE = 32\n",
        "EVAL_BATCH_SIZE = 32\n",
        "PREDICT_BATCH_SIZE = 8\n",
        "LEARNING_RATE = 3e-6\n",
        "WARMUP_PROPORTION = 0.01\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 1000\n",
        "ITERATIONS_PER_LOOP = 1000\n",
        "NUM_TPU_CORES = 8\n",
        "VOCAB_FILE = os.path.join(BERT_PRETRAINED_DIR, 'vocab.txt')\n",
        "CONFIG_FILE = os.path.join(BERT_PRETRAINED_DIR, 'bert_config.json')\n",
        "INIT_CHECKPOINT = os.path.join(BERT_PRETRAINED_DIR, 'bert_model.ckpt')\n",
        "DO_LOWER_CASE = BERT_MODEL.startswith('uncased')\n",
        "\n",
        "processors = {\n",
        "  \"cola\": run_multilabels_classifier.ColaProcessor,\n",
        "  \"mnli\": run_multilabels_classifier.MnliProcessor,\n",
        "  \"mrpc\": run_multilabels_classifier.MrpcProcessor,\n",
        "  \"multilabeltext-2\": run_multilabels_classifier.MultiLabelTextProcessor_original,\n",
        "  \"multilabeltext-1\": run_multilabels_classifier.MultiLabelTextProcessor_original\n",
        "}\n",
        "processor = processors[TASK.lower()]()\n",
        "label_list = processor.get_labels()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=VOCAB_FILE, do_lower_case=DO_LOWER_CASE)\n",
        "\n",
        "tpu_cluster_resolver = tf.contrib.cluster_resolver.TPUClusterResolver(TPU_ADDRESS)\n",
        "run_config = tf.contrib.tpu.RunConfig(\n",
        "    cluster=tpu_cluster_resolver,\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS,\n",
        "    tpu_config=tf.contrib.tpu.TPUConfig(\n",
        "        iterations_per_loop=ITERATIONS_PER_LOOP,\n",
        "        num_shards=NUM_TPU_CORES,\n",
        "        per_host_input_for_training=tf.contrib.tpu.InputPipelineConfig.PER_HOST_V2))\n",
        "\n",
        "train_examples = processor.get_train_examples(TASK_DATA_DIR)\n",
        "num_train_steps = int(\n",
        "    len(train_examples) / TRAIN_BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "model_fn = run_multilabels_classifier.model_fn_builder(\n",
        "    bert_config=modeling.BertConfig.from_json_file(CONFIG_FILE),\n",
        "    num_labels=len(label_list),\n",
        "    init_checkpoint=INIT_CHECKPOINT,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    num_train_steps=num_train_steps,\n",
        "    num_warmup_steps=num_warmup_steps,\n",
        "    use_tpu=True,\n",
        "    use_one_hot_embeddings=True\n",
        ")\n",
        "\n",
        "estimator = tf.contrib.tpu.TPUEstimator(\n",
        "    use_tpu=True,\n",
        "    model_fn=model_fn,\n",
        "    config=run_config,\n",
        "    train_batch_size=TRAIN_BATCH_SIZE,\n",
        "    eval_batch_size=EVAL_BATCH_SIZE,\n",
        "    predict_batch_size = PREDICT_BATCH_SIZE)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Estimator's model_fn (<function model_fn_builder.<locals>.model_fn at 0x7f9f2081ef28>) includes params argument, but params are not passed to Estimator.\n",
            "INFO:tensorflow:Using config: {'_model_dir': 'gs://nlu-naluhodo-bert/bert-tfhub/models/MultiLabelText-1', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 1000, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "cluster_def {\n",
            "  job {\n",
            "    name: \"worker\"\n",
            "    tasks {\n",
            "      key: 0\n",
            "      value: \"10.2.133.226:8470\"\n",
            "    }\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f9ef620b898>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.2.133.226:8470', '_evaluation_master': 'grpc://10.2.133.226:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=1000, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f9ef6662908>}\n",
            "INFO:tensorflow:_TPUContext: eval_on_tpu True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz_K4-a6M9b3",
        "colab_type": "code",
        "outputId": "1c1b4a4c-2e6e-4eee-80a6-57d1e87a19f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 6031
        }
      },
      "source": [
        "# Train the model.\n",
        "print('multilabel-task on BERT base model normally takes about 10-15 minutes. Please wait...')\n",
        "train_file = os.path.join(OUTPUT_DIR, \"train.tf_record\")\n",
        "run_multilabels_classifier.file_based_convert_examples_to_features(\n",
        "    train_examples, label_list, MAX_SEQ_LENGTH, tokenizer, train_file)\n",
        "tf.logging.info(\"***** Running training *****\")\n",
        "tf.logging.info(\"  Num examples = %d\", len(train_examples))\n",
        "tf.logging.info(\"  Batch size = %d\", TRAIN_BATCH_SIZE)\n",
        "tf.logging.info(\"  Num steps = %d\", num_train_steps)\n",
        "train_input_fn = run_multilabels_classifier.file_based_input_fn_builder(\n",
        "    input_file=train_file,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=True)\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "multilabel-task on BERT base model normally takes about 10-15 minutes. Please wait...\n",
            "INFO:tensorflow:Writing example 0 of 1135\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 0\n",
            "INFO:tensorflow:tokens: [CLS] message id java ##mail evans @ thy ##me date mon mar ps ##t from drew f ##oss ##um @ en ##ron com to darrell school ##craft @ en ##ron com subject t ##w gas sales privileged and confidential attorney client privilege cc danny mcc ##arty @ en ##ron com steven harris @ en ##ron com kevin h ##yat ##t @ en ##ron com mi ##me version content type text plain char ##set us as ##ci ##i content transfer encoding bit bc ##c danny mcc ##arty @ en ##ron com steven harris @ en ##ron com kevin h ##yat ##t @ en ##ron com x from drew f ##oss ##um x to darrell school ##craft x cc danny mcc ##arty steven harris kevin h ##yat ##t x bc ##c x folder drew f ##oss ##um dec june notes folder ##s all documents x origin f ##oss ##um d x file ##name d ##fo ##ss ##um ns ##f in anticipation of potential litigation involving t ##w s operational activities please prepare an analysis for me of the reasons for t ##w s sale of excess natural gas at the california border i am aware of several of these sales and have been informed that excess pressure at the border is the basic reason for them i d like a more specific explanation that includes the following information what are the specific pressures and volume considerations that could make it operational ##ly necessary to sell gas at the california border what is the process that is followed [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4471 8909 9262 21397 6473 1030 15177 4168 3058 12256 9388 8827 2102 2013 3881 1042 15094 2819 1030 4372 4948 4012 2000 23158 2082 10419 1030 4372 4948 4012 3395 1056 2860 3806 4341 21598 1998 18777 4905 7396 14293 10507 6266 23680 23871 1030 4372 4948 4012 7112 5671 1030 4372 4948 4012 4901 1044 26139 2102 1030 4372 4948 4012 2771 4168 2544 4180 2828 3793 5810 25869 13462 2149 2004 6895 2072 4180 4651 17181 2978 4647 2278 6266 23680 23871 1030 4372 4948 4012 7112 5671 1030 4372 4948 4012 4901 1044 26139 2102 1030 4372 4948 4012 1060 2013 3881 1042 15094 2819 1060 2000 23158 2082 10419 1060 10507 6266 23680 23871 7112 5671 4901 1044 26139 2102 1060 4647 2278 1060 19622 3881 1042 15094 2819 11703 2238 3964 19622 2015 2035 5491 1060 4761 1042 15094 2819 1040 1060 5371 18442 1040 14876 4757 2819 24978 2546 1999 11162 1997 4022 15382 5994 1056 2860 1055 6515 3450 3531 7374 2019 4106 2005 2033 1997 1996 4436 2005 1056 2860 1055 5096 1997 9987 3019 3806 2012 1996 2662 3675 1045 2572 5204 1997 2195 1997 2122 4341 1998 2031 2042 6727 2008 9987 3778 2012 1996 3675 2003 1996 3937 3114 2005 2068 1045 1040 2066 1037 2062 3563 7526 2008 2950 1996 2206 2592 2054 2024 1996 3563 15399 1998 3872 16852 2008 2071 2191 2009 6515 2135 4072 2000 5271 3806 2012 1996 2662 3675 2054 2003 1996 2832 2008 2003 2628 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: [1, 0, 0, 0, 0, 0] (id = [1, 0, 0, 0, 0, 0])\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 1\n",
            "INFO:tensorflow:tokens: [CLS] message id java ##mail evans @ thy ##me date tu ##e mar ps ##t from drew f ##oss ##um @ en ##ron com to julia white @ en ##ron com steven january @ en ##ron com subject t ##w gas sales privileged and confidential attorney client privilege cc darrell school ##craft @ en ##ron com mi ##me version content type text plain char ##set us as ##ci ##i content transfer encoding bit bc ##c darrell school ##craft @ en ##ron com x from drew f ##oss ##um x to julia white steven january x cc darrell school ##craft x bc ##c x folder drew f ##oss ##um dec june notes folder ##s all documents x origin f ##oss ##um d x file ##name d ##fo ##ss ##um ns ##f julia and steve here are some questions i ve sent to darrell on the t ##w cal border line pack sales i d like him to pull in the right people to get me the answers so we will be prepared if we need to explain these events darrell i thought i d better let your bosses know that i ve been putting more stuff on your already full plate thanks all d ##f forward ##ed by drew f ##oss ##um et s en ##ron on am drew f ##oss ##um pm to darrell school ##craft et s en ##ron @ en ##ron cc danny mcc ##arty et s en ##ron @ en ##ron steven harris et s en ##ron @ en ##ron kevin h [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4471 8909 9262 21397 6473 1030 15177 4168 3058 10722 2063 9388 8827 2102 2013 3881 1042 15094 2819 1030 4372 4948 4012 2000 6423 2317 1030 4372 4948 4012 7112 2254 1030 4372 4948 4012 3395 1056 2860 3806 4341 21598 1998 18777 4905 7396 14293 10507 23158 2082 10419 1030 4372 4948 4012 2771 4168 2544 4180 2828 3793 5810 25869 13462 2149 2004 6895 2072 4180 4651 17181 2978 4647 2278 23158 2082 10419 1030 4372 4948 4012 1060 2013 3881 1042 15094 2819 1060 2000 6423 2317 7112 2254 1060 10507 23158 2082 10419 1060 4647 2278 1060 19622 3881 1042 15094 2819 11703 2238 3964 19622 2015 2035 5491 1060 4761 1042 15094 2819 1040 1060 5371 18442 1040 14876 4757 2819 24978 2546 6423 1998 3889 2182 2024 2070 3980 1045 2310 2741 2000 23158 2006 1996 1056 2860 10250 3675 2240 5308 4341 1045 1040 2066 2032 2000 4139 1999 1996 2157 2111 2000 2131 2033 1996 6998 2061 2057 2097 2022 4810 2065 2057 2342 2000 4863 2122 2824 23158 1045 2245 1045 1040 2488 2292 2115 23029 2113 2008 1045 2310 2042 5128 2062 4933 2006 2115 2525 2440 5127 4283 2035 1040 2546 2830 2098 2011 3881 1042 15094 2819 3802 1055 4372 4948 2006 2572 3881 1042 15094 2819 7610 2000 23158 2082 10419 3802 1055 4372 4948 1030 4372 4948 10507 6266 23680 23871 3802 1055 4372 4948 1030 4372 4948 7112 5671 3802 1055 4372 4948 1030 4372 4948 4901 1044 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: [1, 0, 0, 0, 0, 1] (id = [1, 0, 0, 0, 0, 1])\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 2\n",
            "INFO:tensorflow:tokens: [CLS] message id java ##mail evans @ thy ##me date mon mar ps ##t from drew f ##oss ##um @ en ##ron com to darrell school ##craft @ en ##ron com subject t ##w gas sales privileged and confidential attorney client privilege cc danny mcc ##arty @ en ##ron com steven harris @ en ##ron com kevin h ##yat ##t @ en ##ron com mi ##me version content type text plain char ##set us as ##ci ##i content transfer encoding bit bc ##c danny mcc ##arty @ en ##ron com steven harris @ en ##ron com kevin h ##yat ##t @ en ##ron com x from drew f ##oss ##um x to darrell school ##craft darrell school ##craft et s en ##ron @ en ##ron x cc danny mcc ##arty danny mcc ##arty et s en ##ron @ en ##ron steven harris steven harris et s en ##ron @ en ##ron kevin h ##yat ##t kevin h ##yat ##t en ##ron @ en ##ron ##x ##gate x bc ##c x folder d ##fo ##ss ##um non privileged f ##oss ##um drew sent mail x origin f ##oss ##um d x file ##name d ##fo ##ss ##um non privileged ps ##t in anticipation of potential litigation involving t ##w s operational activities please prepare an analysis for me of the reasons for t ##w s sale of excess natural gas at the california border i am aware of several of these sales and have been informed that excess pressure at the border is the basic reason [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4471 8909 9262 21397 6473 1030 15177 4168 3058 12256 9388 8827 2102 2013 3881 1042 15094 2819 1030 4372 4948 4012 2000 23158 2082 10419 1030 4372 4948 4012 3395 1056 2860 3806 4341 21598 1998 18777 4905 7396 14293 10507 6266 23680 23871 1030 4372 4948 4012 7112 5671 1030 4372 4948 4012 4901 1044 26139 2102 1030 4372 4948 4012 2771 4168 2544 4180 2828 3793 5810 25869 13462 2149 2004 6895 2072 4180 4651 17181 2978 4647 2278 6266 23680 23871 1030 4372 4948 4012 7112 5671 1030 4372 4948 4012 4901 1044 26139 2102 1030 4372 4948 4012 1060 2013 3881 1042 15094 2819 1060 2000 23158 2082 10419 23158 2082 10419 3802 1055 4372 4948 1030 4372 4948 1060 10507 6266 23680 23871 6266 23680 23871 3802 1055 4372 4948 1030 4372 4948 7112 5671 7112 5671 3802 1055 4372 4948 1030 4372 4948 4901 1044 26139 2102 4901 1044 26139 2102 4372 4948 1030 4372 4948 2595 5867 1060 4647 2278 1060 19622 1040 14876 4757 2819 2512 21598 1042 15094 2819 3881 2741 5653 1060 4761 1042 15094 2819 1040 1060 5371 18442 1040 14876 4757 2819 2512 21598 8827 2102 1999 11162 1997 4022 15382 5994 1056 2860 1055 6515 3450 3531 7374 2019 4106 2005 2033 1997 1996 4436 2005 1056 2860 1055 5096 1997 9987 3019 3806 2012 1996 2662 3675 1045 2572 5204 1997 2195 1997 2122 4341 1998 2031 2042 6727 2008 9987 3778 2012 1996 3675 2003 1996 3937 3114 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: [1, 0, 0, 0, 0, 0] (id = [1, 0, 0, 0, 0, 0])\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 3\n",
            "INFO:tensorflow:tokens: [CLS] message id java ##mail evans @ thy ##me date wed feb ps ##t from legal ##on ##line compliance @ en ##ron com to ne ##me ##c @ mail ##man en ##ron com gerald ne ##me ##c @ en ##ron com subject confidential information and securities trading mi ##me version content type text plain char ##set an ##si x content transfer encoding bit x from office of the chairman en ##ron wholesale services legal ##on ##line compliance @ en ##ron com x to ne ##me ##c @ mail ##man en ##ron com gerald gerald ne ##me ##c @ en ##ron com x cc x bc ##c x folder gerald ne ##me ##c dec june notes folder ##s all documents x origin ne ##me ##c g x file ##name g ##nem ##ec ns ##f to ne ##me ##c gerald email gerald ne ##me ##c @ en ##ron com en ##ron wholesale services office of the chairman from mark fr ##ever ##t chairman ceo greg w ##hall ##ey president co ##o mark ha ##ed ##ick ##e managing director general counsel subject confidential information and securities trading en ##ron wholesale services e ##ws maintains official policies and procedures regarding confidential information and securities trading policies and procedures which have been revised as of november to reflect the new e ##ws structure these policies and procedures are intended to allow us simultaneously to pursue our diverse businesses and to protect confidential information our reputation for integrity and e ##ws and its employees from legal liability you are required to [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4471 8909 9262 21397 6473 1030 15177 4168 3058 21981 13114 8827 2102 2013 3423 2239 4179 12646 1030 4372 4948 4012 2000 11265 4168 2278 1030 5653 2386 4372 4948 4012 9659 11265 4168 2278 1030 4372 4948 4012 3395 18777 2592 1998 12012 6202 2771 4168 2544 4180 2828 3793 5810 25869 13462 2019 5332 1060 4180 4651 17181 2978 1060 2013 2436 1997 1996 3472 4372 4948 17264 2578 3423 2239 4179 12646 1030 4372 4948 4012 1060 2000 11265 4168 2278 1030 5653 2386 4372 4948 4012 9659 9659 11265 4168 2278 1030 4372 4948 4012 1060 10507 1060 4647 2278 1060 19622 9659 11265 4168 2278 11703 2238 3964 19622 2015 2035 5491 1060 4761 11265 4168 2278 1043 1060 5371 18442 1043 25832 8586 24978 2546 2000 11265 4168 2278 9659 10373 9659 11265 4168 2278 1030 4372 4948 4012 4372 4948 17264 2578 2436 1997 1996 3472 2013 2928 10424 22507 2102 3472 5766 6754 1059 9892 3240 2343 2522 2080 2928 5292 2098 6799 2063 6605 2472 2236 9517 3395 18777 2592 1998 12012 6202 4372 4948 17264 2578 1041 9333 9319 2880 6043 1998 8853 4953 18777 2592 1998 12012 6202 6043 1998 8853 2029 2031 2042 8001 2004 1997 2281 2000 8339 1996 2047 1041 9333 3252 2122 6043 1998 8853 2024 3832 2000 3499 2149 7453 2000 7323 2256 7578 5661 1998 2000 4047 18777 2592 2256 5891 2005 11109 1998 1041 9333 1998 2049 5126 2013 3423 14000 2017 2024 3223 2000 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: [1, 0, 0, 0, 0, 0] (id = [1, 0, 0, 0, 0, 0])\n",
            "INFO:tensorflow:*** Example ***\n",
            "INFO:tensorflow:guid: 4\n",
            "INFO:tensorflow:tokens: [CLS] message id java ##mail evans @ thy ##me date wed oct pd ##t from steven ke ##an @ en ##ron com to paul kaufman @ en ##ron com susan mara @ en ##ron com jeff das ##ovich @ en ##ron com mona pet ##ro ##ch ##ko @ en ##ron com sandra mcc ##ub ##bin @ en ##ron com subject made ##ra ranch press release cc richard shapiro @ en ##ron com mi ##me version content type text plain char ##set us as ##ci ##i content transfer encoding bit bc ##c richard shapiro @ en ##ron com x from steven j ke ##an x to paul kaufman susan j mara jeff das ##ovich mona l pet ##ro ##ch ##ko sandra mcc ##ub ##bin x cc richard shapiro x bc ##c x folder jeff das ##ovich dec notes folder ##s all documents x origin das ##ovich j x file ##name jd ##as ##ovic ns ##f heads up this is not to be discussed in advance out side of en ##ron but you guys need to know if there are ways we can be helpful call carolyn green to discuss forward ##ed by steven j ke ##an ho ##u ee ##s on pm mark palmer @ en ##ron am to steven j ke ##an ho ##u ee ##s @ ee ##s cc subject made ##ra ranch press release this will touch off a fires ##torm diane is doing a good job retaining mc ##nally temple in ca and even getting some message development help from our old [SEP]\n",
            "INFO:tensorflow:input_ids: 101 4471 8909 9262 21397 6473 1030 15177 4168 3058 21981 13323 22851 2102 2013 7112 17710 2319 1030 4372 4948 4012 2000 2703 23699 1030 4372 4948 4012 6294 13955 1030 4372 4948 4012 5076 8695 12303 1030 4372 4948 4012 13813 9004 3217 2818 3683 1030 4372 4948 4012 12834 23680 12083 8428 1030 4372 4948 4012 3395 2081 2527 8086 2811 2713 10507 2957 24630 1030 4372 4948 4012 2771 4168 2544 4180 2828 3793 5810 25869 13462 2149 2004 6895 2072 4180 4651 17181 2978 4647 2278 2957 24630 1030 4372 4948 4012 1060 2013 7112 1046 17710 2319 1060 2000 2703 23699 6294 1046 13955 5076 8695 12303 13813 1048 9004 3217 2818 3683 12834 23680 12083 8428 1060 10507 2957 24630 1060 4647 2278 1060 19622 5076 8695 12303 11703 3964 19622 2015 2035 5491 1060 4761 8695 12303 1046 1060 5371 18442 26219 3022 9142 24978 2546 4641 2039 2023 2003 2025 2000 2022 6936 1999 5083 2041 2217 1997 4372 4948 2021 2017 4364 2342 2000 2113 2065 2045 2024 3971 2057 2064 2022 14044 2655 15611 2665 2000 6848 2830 2098 2011 7112 1046 17710 2319 7570 2226 25212 2015 2006 7610 2928 8809 1030 4372 4948 2572 2000 7112 1046 17710 2319 7570 2226 25212 2015 1030 25212 2015 10507 3395 2081 2527 8086 2811 2713 2023 2097 3543 2125 1037 8769 20654 12082 2003 2725 1037 2204 3105 12823 11338 26827 3379 1999 6187 1998 2130 2893 2070 4471 2458 2393 2013 2256 2214 102\n",
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            "INFO:tensorflow:label: [1, 0, 0, 0, 0, 0] (id = [1, 0, 0, 0, 0, 0])\n",
            "INFO:tensorflow:***** Running training *****\n",
            "INFO:tensorflow:  Num examples = 1135\n",
            "INFO:tensorflow:  Batch size = 32\n",
            "INFO:tensorflow:  Num steps = 14187\n",
            "INFO:tensorflow:Querying Tensorflow master (grpc://10.2.133.226:8470) for TPU system metadata.\n",
            "INFO:tensorflow:Found TPU system:\n",
            "INFO:tensorflow:*** Num TPU Cores: 8\n",
            "INFO:tensorflow:*** Num TPU Workers: 1\n",
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 15713879670663694203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 17667312031214739020)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 7259243042589462203)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 3063187338904789856)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 2773942055403689470)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 5664809989900726935)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 100087510466400996)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 7264435289128316276)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 8767581307475779826)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 932489684604596695)\n",
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 17179869184, 4537793796198685419)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "INFO:tensorflow:Calling model_fn.\n",
            "WARNING:tensorflow:From bert_repo/run_multilabels_classifier.py:649: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.experimental.map_and_batch(...)`.\n",
            "WARNING:tensorflow:From bert_repo/run_multilabels_classifier.py:629: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "INFO:tensorflow:*** Features ***\n",
            "INFO:tensorflow:  name = input_ids, shape = (4, 256)\n",
            "INFO:tensorflow:  name = input_mask, shape = (4, 256)\n",
            "INFO:tensorflow:  name = is_real_example, shape = (4,)\n",
            "INFO:tensorflow:  name = label_ids, shape = (4, 6)\n",
            "INFO:tensorflow:  name = segment_ids, shape = (4, 256)\n",
            "WARNING:tensorflow:From bert_repo/modeling.py:358: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From bert_repo/modeling.py:671: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use keras.layers.dense instead.\n",
            "INFO:tensorflow:num_labels:6;logits:Tensor(\"loss/BiasAdd:0\", shape=(4, 6), dtype=float32);labels:Tensor(\"loss/Cast:0\", shape=(4, 6), dtype=float32)\n",
            "INFO:tensorflow:**** Trainable Variables ****\n",
            "INFO:tensorflow:  name = bert/embeddings/word_embeddings:0, shape = (30522, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/token_type_embeddings:0, shape = (2, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/position_embeddings:0, shape = (512, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/embeddings/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_0/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_1/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_2/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_3/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_4/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_5/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_6/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_7/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_8/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_9/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_10/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/query/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/key/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/self/value/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/attention/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/kernel:0, shape = (768, 3072), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/intermediate/dense/bias:0, shape = (3072,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/kernel:0, shape = (3072, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/beta:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/encoder/layer_11/output/LayerNorm/gamma:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/kernel:0, shape = (768, 768), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = bert/pooler/dense/bias:0, shape = (768,), *INIT_FROM_CKPT*\n",
            "INFO:tensorflow:  name = output_weights:0, shape = (6, 768)\n",
            "INFO:tensorflow:  name = output_bias:0, shape = (6,)\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/learning_rate_decay_v2.py:321: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "INFO:tensorflow:Create CheckpointSaverHook.\n",
            "INFO:tensorflow:Done calling model_fn.\n",
            "INFO:tensorflow:TPU job name worker\n",
            "INFO:tensorflow:Graph was finalized.\n",
            "INFO:tensorflow:Running local_init_op.\n",
            "INFO:tensorflow:Done running local_init_op.\n",
            "INFO:tensorflow:Saving checkpoints for 0 into gs://nlu-naluhodo-bert/bert-tfhub/models/MultiLabelText-1/model.ckpt.\n",
            "INFO:tensorflow:Initialized dataset iterators in 0 seconds\n",
            "INFO:tensorflow:Installing graceful shutdown hook.\n",
            "INFO:tensorflow:Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
            "INFO:tensorflow:Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
            "\n",
            "INFO:tensorflow:Init TPU system\n",
            "INFO:tensorflow:Initialized TPU in 7 seconds\n",
            "INFO:tensorflow:Starting infeed thread controller.\n",
            "INFO:tensorflow:Starting outfeed thread controller.\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 1000 into gs://nlu-naluhodo-bert/bert-tfhub/models/MultiLabelText-1/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.10906406, step = 1000\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 2000 into gs://nlu-naluhodo-bert/bert-tfhub/models/MultiLabelText-1/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.08373821, step = 2000 (107.868 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.27062\n",
            "INFO:tensorflow:examples/sec: 296.66\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 3000 into gs://nlu-naluhodo-bert/bert-tfhub/models/MultiLabelText-1/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.26896924, step = 3000 (102.814 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.72624\n",
            "INFO:tensorflow:examples/sec: 311.24\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 4000 into gs://nlu-naluhodo-bert/bert-tfhub/models/MultiLabelText-1/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.23101023, step = 4000 (101.737 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.82932\n",
            "INFO:tensorflow:examples/sec: 314.538\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 5000 into gs://nlu-naluhodo-bert/bert-tfhub/models/MultiLabelText-1/model.ckpt.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:966: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n",
            "INFO:tensorflow:loss = 0.0431891, step = 5000 (106.046 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.42983\n",
            "INFO:tensorflow:examples/sec: 301.754\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 6000 into gs://nlu-naluhodo-bert/bert-tfhub/models/MultiLabelText-1/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.0052397363, step = 6000 (100.796 sec)\n",
            "INFO:tensorflow:global_step/sec: 9.92103\n",
            "INFO:tensorflow:examples/sec: 317.473\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 7000 into gs://nlu-naluhodo-bert/bert-tfhub/models/MultiLabelText-1/model.ckpt.\n",
            "INFO:tensorflow:loss = 0.0091513395, step = 7000 (112.535 sec)\n",
            "INFO:tensorflow:global_step/sec: 8.88606\n",
            "INFO:tensorflow:examples/sec: 284.354\n",
            "INFO:tensorflow:Enqueue next (1000) batch(es) of data to infeed.\n",
            "INFO:tensorflow:Dequeue next (1000) batch(es) of data from outfeed.\n",
            "INFO:tensorflow:Saving checkpoints for 8000 into gs://nlu-naluhodo-bert/bert-tfhub/models/MultiLabelText-1/model.ckpt.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-vKvNC8szYM6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Eval the model.\n",
        "eval_examples = processor.get_dev_examples(TASK_DATA_DIR)\n",
        "num_actual_eval_examples = len(eval_examples)\n",
        "use_tpu = True\n",
        "# if use_tpu:\n",
        "#     # TPU requires a fixed batch size for all batches, therefore the number\n",
        "#     # of examples must be a multiple of the batch size, or else examples\n",
        "#     # will get dropped. So we pad with fake examples which are ignored\n",
        "#     # later on. These do NOT count towards the metric (all tf.metrics\n",
        "#     # support a per-instance weight, and these get a weight of 0.0).\n",
        "#     while len(eval_examples) % EVAL_BATCH_SIZE != 0:\n",
        "#         eval_examples.append(run_multilabels_classifier.PaddingInputExample())\n",
        "\n",
        "eval_file = os.path.join(OUTPUT_DIR, \"eval.tf_record\")\n",
        "run_multilabels_classifier.file_based_convert_examples_to_features(\n",
        "    eval_examples, label_list, MAX_SEQ_LENGTH, tokenizer, eval_file)\n",
        "\n",
        "tf.logging.info(\"***** Running evaluation *****\")\n",
        "tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
        "                len(eval_examples), num_actual_eval_examples,\n",
        "                len(eval_examples) - num_actual_eval_examples)\n",
        "tf.logging.info(\"  Batch size = %d\", EVAL_BATCH_SIZE)\n",
        "\n",
        "# This tells the estimator to run through the entire set.\n",
        "eval_steps = int(len(eval_examples) // EVAL_BATCH_SIZE)\n",
        "# However, if running eval on the TPU, you will need to specify the\n",
        "# number of steps.\n",
        "\n",
        "eval_drop_remainder = True if use_tpu else False\n",
        "eval_input_fn = run_multilabels_classifier.file_based_input_fn_builder(\n",
        "    input_file=eval_file,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=eval_drop_remainder)\n",
        "\n",
        "result = estimator.evaluate(input_fn=eval_input_fn, steps=eval_steps)\n",
        "\n",
        "output_eval_file = os.path.join(OUTPUT_DIR, \"eval_results.txt\")\n",
        "with tf.gfile.GFile(output_eval_file, \"w\") as writer:\n",
        "    tf.logging.info(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "        tf.logging.info(\"  %s = %s\", key, str(result[key]))\n",
        "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9E4n27RVGoV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict by the model.\n",
        "predict_examples = processor.get_test_examples(TASK_DATA_DIR)\n",
        "num_actual_predict_examples = len(predict_examples)\n",
        "\n",
        "# if use_tpu:\n",
        "#     # TPU requires a fixed batch size for all batches, therefore the number\n",
        "#     # of examples must be a multiple of the batch size, or else examples\n",
        "#     # will get dropped. So we pad with fake examples which are ignored\n",
        "#     # later on.\n",
        "#     while len(predict_examples) % PREDICT_BATCH_SIZE != 0:\n",
        "#         predict_examples.append(run_multilabels_classifier.PaddingInputExample())\n",
        "\n",
        "predict_file = os.path.join(OUTPUT_DIR, \"predict.tf_record\")\n",
        "run_multilabels_classifier.file_based_convert_examples_to_features(predict_examples, label_list,\n",
        "                                        MAX_SEQ_LENGTH, tokenizer,\n",
        "                                        predict_file)\n",
        "\n",
        "tf.logging.info(\"***** Running prediction*****\")\n",
        "tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
        "                len(predict_examples), num_actual_predict_examples,\n",
        "                len(predict_examples) - num_actual_predict_examples)\n",
        "tf.logging.info(\"  Batch size = %d\", PREDICT_BATCH_SIZE)\n",
        "\n",
        "predict_drop_remainder = True if use_tpu else False\n",
        "predict_input_fn = run_multilabels_classifier.file_based_input_fn_builder(\n",
        "    input_file=predict_file,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=predict_drop_remainder)\n",
        "\n",
        "\n",
        "result = estimator.predict(input_fn=predict_input_fn)\n",
        "output_predict_file = os.path.join(OUTPUT_DIR, \"test_results.tsv\")\n",
        "\n",
        "pred = []\n",
        "with tf.gfile.GFile(output_predict_file, \"w\") as writer:\n",
        "    num_written_lines = 0\n",
        "    tf.logging.info(\"***** Predict results *****\")\n",
        "    for (i, prediction) in enumerate(result):\n",
        "        probabilities = prediction[\"probabilities\"]\n",
        "        pred.append((test[i][0], probabilities, test[i][1:]))\n",
        "        if i >= num_actual_predict_examples:\n",
        "            break\n",
        "        output_line = \",\".join(str(class_probability) for class_probability in probabilities) + \"\\n\"\n",
        "        writer.write(str(predict_examples[i].guid) + ',' + output_line)\n",
        "        num_written_lines += 1\n",
        "        \n",
        "pickle.dump(pred, open(\"pred.p\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "giGjMqmO_rGP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred[:5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kE01dA98Gu10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cd /content/nlu-naluhodo"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEjMJEO3KuNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mv data/train.csv  data/test.csv"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtSODwOsJnab",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict by the model by training data.\n",
        "test = beeap_1.iloc[train_idx][['Contents','1', '2', '3', '4', '5', '6']].values\n",
        "predict_examples = processor.get_test_examples(TASK_DATA_DIR)\n",
        "num_actual_predict_examples = len(predict_examples)\n",
        "\n",
        "# if use_tpu:\n",
        "#     # TPU requires a fixed batch size for all batches, therefore the number\n",
        "#     # of examples must be a multiple of the batch size, or else examples\n",
        "#     # will get dropped. So we pad with fake examples which are ignored\n",
        "#     # later on.\n",
        "#     while len(predict_examples) % PREDICT_BATCH_SIZE != 0:\n",
        "#         predict_examples.append(run_multilabels_classifier.PaddingInputExample())\n",
        "\n",
        "predict_file = os.path.join(OUTPUT_DIR, \"predict.tf_record\")\n",
        "run_multilabels_classifier.file_based_convert_examples_to_features(predict_examples, label_list,\n",
        "                                        MAX_SEQ_LENGTH, tokenizer,\n",
        "                                        predict_file)\n",
        "\n",
        "tf.logging.info(\"***** Running prediction*****\")\n",
        "tf.logging.info(\"  Num examples = %d (%d actual, %d padding)\",\n",
        "                len(predict_examples), num_actual_predict_examples,\n",
        "                len(predict_examples) - num_actual_predict_examples)\n",
        "tf.logging.info(\"  Batch size = %d\", PREDICT_BATCH_SIZE)\n",
        "\n",
        "predict_drop_remainder = True if use_tpu else False\n",
        "predict_input_fn = run_multilabels_classifier.file_based_input_fn_builder(\n",
        "    input_file=predict_file,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=predict_drop_remainder)\n",
        "\n",
        "\n",
        "result = estimator.predict(input_fn=predict_input_fn)\n",
        "output_predict_file = os.path.join(OUTPUT_DIR, \"test_results.tsv\")\n",
        "\n",
        "pred_train = []\n",
        "with tf.gfile.GFile(output_predict_file, \"w\") as writer:\n",
        "    num_written_lines = 0\n",
        "    tf.logging.info(\"***** Predict results *****\")\n",
        "    for (i, prediction) in enumerate(result):\n",
        "        probabilities = prediction[\"probabilities\"]\n",
        "        pred_train.append((test[i][0], probabilities, test[i][1:]))\n",
        "        if i >= num_actual_predict_examples:\n",
        "            break\n",
        "        output_line = \",\".join(str(class_probability) for class_probability in probabilities) + \"\\n\"\n",
        "        writer.write(str(predict_examples[i].guid) + ',' + output_line)\n",
        "        num_written_lines += 1\n",
        "        \n",
        "pickle.dump(pred, open(\"pred_train.p\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWoLnUWJHsgw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from eval.evaluation import pred_classes_dt, pred_classes_f1, plot_roc_curve, \\\n",
        "  plot_confusion_matrix\n",
        "\n",
        "from sklearn.metrics import f1_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pFSd14PZxCe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def extract(pred, k):\n",
        "  res = []\n",
        "  for p in pred:\n",
        "    res.append(p[k])\n",
        "  return np.array(res, dtype = float)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21EAzyTuI1aY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "predictions = extract(pred, 1)\n",
        "train_pred =  extract(pred_train, 1)\n",
        "y_train = extract(pred_train, 2)\n",
        "y_test =  extract(pred, 2)\n",
        "\n",
        "y_pred_dt = pred_classes_dt(train_pred, y_train, predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bWlQR3KWJRIt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred_dt = pred_classes_dt(train_pred, y_train, predictions)\n",
        "print('macro F1 score: {0:0.4f}'.format(f1_score(y_test, y_pred_dt, average='macro')))\n",
        "print('micro F1 score: {0:0.4f}'.format(f1_score(y_test, y_pred_dt, average='micro')))\n",
        "\n",
        "\n",
        "y_pred_f1 = pred_classes_f1(train_pred, y_train,predictions)\n",
        "print('macro F1 score: {0:0.4f}'.format(f1_score(y_test, y_pred_f1, average='macro')))\n",
        "print('micro F1 score: {0:0.4f}'.format(f1_score(y_test, y_pred_f1, average='micro')))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V4XHmSkVMJaK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plot_roc_curve(y_test, predictions,  title='ROC Curves for Coarse Genre', micro=True, per_class=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWfMZw9wcSZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "res = {'y_test': y_test, 'y_test_pred': predictions, 'y_train_pred':train_pred, 'y_train':y_train}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DF0-Fo_XcSRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(res, open(\"bert_result.p\", \"wb\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-MF_wCnfUWGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Export the model\n",
        "# def serving_input_fn():\n",
        "#   with tf.variable_scope(\"foo\"):\n",
        "#     feature_spec = {\n",
        "#         \"input_ids\": tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),\n",
        "#         \"input_mask\": tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),\n",
        "#         \"segment_ids\": tf.FixedLenFeature([MAX_SEQ_LENGTH], tf.int64),\n",
        "#         \"label_ids\": tf.FixedLenFeature([6], tf.int64),\n",
        "#       }\n",
        "#     serialized_tf_example = tf.placeholder(dtype=tf.string,\n",
        "#                                            shape=[None],\n",
        "#                                            name='input_example_tensor')\n",
        "#     receiver_tensors = {'examples': serialized_tf_example}\n",
        "#     features = tf.parse_example(serialized_tf_example, feature_spec)\n",
        "#     return tf.estimator.export.ServingInputReceiver(features, receiver_tensors)\n",
        "\n",
        "# EXPORT_DIR = 'gs://{}/bert/export/{}'.format(BUCKET, TASK)\n",
        "# estimator._export_to_tpu = False  # this is important\n",
        "# path = estimator.export_savedmodel(EXPORT_DIR, serving_input_fn)\n",
        "# print(path)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKZnbtpIU6mO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# !saved_model_cli show --all --dir gs://nlu-naluhodo-bert/bert/export/MultiLabelText/1557283389"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMRjdCre0ONZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}